namespace com.ibm.streamsx.kafka.sample;

use com.ibm.streamsx.kafka::KafkaConsumer;
use com.ibm.streamsx.kafka::KafkaProducer;
use com.ibm.streamsx.avro::TupleToAvro;
use com.ibm.streamsx.avro::AvroToJSON;
use com.ibm.streamsx.kafka::MessageType;

/*
 * This sample uses AVRO blob for message.
 */
public composite KafkaAvroSample
{
	type
		tweetT = rstring username, rstring tweet, int64 tweettime;

	graph
		// Generate 100 tweets with a changing value for every tweet
		stream<tweetT> GenerateTweet = Beacon() {
			param
				iterations: 100u;
			output
				GenerateTweet : username = "Frank", tweet = "Hi, this is a cool tweet! "
					+(rstring) IterationCount(), tweettime = (int64)(1048298232ul + IterationCount());
		}

		// Batch the incoming tuples into Avro tuples with embedded schema
		stream<MessageType.BlobMessage> ConvertToAvro = TupleToAvro(GenerateTweet) {
			param
				outputAvroMessage: "message";
				avroMessageSchemaFile: getThisToolkitDir()+"/etc/twitter.avsc";
				embedAvroSchema: true;
				bytesPerMessage: 2000l;
		}

		// Set value for the key attribute
		stream<MessageType.BlobMessage> AvroMessages as O = Custom(ConvertToAvro as I) {
			logic
				onTuple I:{
					I.key = "sample-key";
					submit(I, O);
				}
		}

		() as KafkaProducer1 = KafkaProducer(AvroMessages) {
			param
				topic : "test" ;
				propertiesFile : "etc/producer.properties";
		}


		// messages get de-serialized into blob
		stream <MessageType.BlobMessage> ReceivedMessages = KafkaConsumer() {
			param
				topic : "test" ;
				propertiesFile : "etc/consumer.properties";
		}

		// Convert the blob to JSON
		stream<rstring jsonMessage> ConvertAvroToJson = AvroToJSON(ReceivedMessages) {
			param
				inputAvroMessage: "message";
		}

		// Display the retrieved JSON message
		() as DisplayJson = Custom(ConvertAvroToJson as I) {
			logic
				onTuple I: println((rstring) I);
		}

}

