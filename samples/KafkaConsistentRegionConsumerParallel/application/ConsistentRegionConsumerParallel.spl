namespace application ;

use com.ibm.streamsx.kafka::* ;
/**
 * Read from a three-partition Kafka topic using the KafkaConsumer operator 
 * in a consistent region (guaranteed tuple processing). This sample contains
 * two consistent regions. The first includes the beacon and the KafkaProducer, 
 * the second includes the three parallel KafkaConsumers and the MessagePrinter. 
 * Kafka only guarantees ordering of tuples within a single partition. This application
 * provided the same guarantee, but since we are reading from three separate partitions, 
 * we can lose order. Depending on the key/message, order can be recovered after consuming
 * from a Kafka Server. 
 * 
 * Make sure you have created your topic before launching:
 *   bin/kafka-topics.sh --create --zookeeper <zk.Host.1>:2181 --partitions 3 --topic myParallelTopic
 * 
 * Edit the consumer.properties and producer.properties files found in the etc directory to include
 * your Kafka properties. 
 * 
 * Build using Studio or the provided Makefile. 
 * 
 * Check results by looking at messagesReceived.out in the data directory. 
 * 
 * Consistent Region does not support Standalone mode, so this sample is only interesting in 
 * Distributed mode. 
 * 
 * TO REMOVE CONSISTENT REGION: remove @consistent annotations (there are two) and 
 * delete JobControlPlane operator.  
 */
composite ConsistentRegionParallelConsumers
{
	param 
		expression<rstring> $topic : "myParallelTopic";
	graph
		//generate data to be written to a kafka server
		@consistent(trigger = operatorDriven)
		stream<rstring topic, rstring key, rstring message> OutputStream = Beacon()
		{
			param
				period : 0.25 ;
				initDelay : 4.0 ;
				triggerCount : 20u ;
			output
				OutputStream : topic = $topic, message =(rstring)
					"Your theory is crazy, but it's not crazy enough to be true. -Niels Bohr", key =(rstring)(int32)(random() * 10.0) ;
			}
		
		//Write to Kafka Server
		() as KafkaSinkOp = KafkaProducer(OutputStream)
			{
				param
					propertiesFile : "etc/producer.properties" ;
			}

		//Read in from a kafka server with a 3-partition topic and start consistent region
		@parallel(width = 3) @consistent(trigger = periodic, period = 5.0)
		stream<rstring message, rstring key> KafkaConsumerOut = KafkaConsumer()
		{
			param
				propertiesFile : "etc/consumer.properties" ;
				topic : $topic;
				partition : getChannel() ;
		}

		
		//Print out data to a file
		() as MessagePrinter = FileSink(KafkaConsumerOut)
		{
			param
				file : "messagesReceived.out" ;
				flush : 1u ;
				format : csv ;
		}

		() as JCP = JobControlPlane()
			{
			}

	}

